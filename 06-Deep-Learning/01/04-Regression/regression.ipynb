{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Deep Learning week - Day 1 - Regression\n",
    "\n",
    "### Exercise objectives:\n",
    "- Write a Neural Network suited for a regression\n",
    "- Optimize the model with the right loss and metrics\n",
    "\n",
    "<hr>\n",
    "<hr>\n",
    "\n",
    "The overall objective of this exercise is to predict the house pricing in the Boston area (USA) based on the input features. This will be done with a Neural Network.\n",
    "\n",
    "The intention of this exercise is to :\n",
    "- prepare the data for a NN (Neural Network)\n",
    "- train a _regression_ NN\n",
    "- check the NN loss during the training and adapt accordingly\n",
    "- select the hyperparameters of the NN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data\n",
    "\n",
    "We will predict the price of houses in Boston and suburbs, based on input variables as the is the pupil-teacher ratio (in the related town), nitric oxides concentration, the crime rate per capita or the weighted distances to five Boston employment centers.\n",
    "\n",
    "You can check additional information about the dataset here https://towardsdatascience.com/machine-learning-project-predicting-boston-house-prices-with-regression-b4e47493633d\n",
    "\n",
    "This classic dataset is provided in the Keras library. It can be loaded as follows : "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.datasets import boston_housing\n",
    "\n",
    "(X_train, y_train), (X_test, y_test) = boston_housing.load_data()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`shape` is an interesting attribute of the data object. It gives the (row, column) shape of the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Size of training data: {}\".format(X_train.shape))\n",
    "print(\"Size of test data: {}\".format(X_test.shape))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "❓ **Question** ❓ What kind of Machine Learning is this problem related to? Supervised, regression, unsupervised, clustering, classification, ... ?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### YOUR ANSWER HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "For reason we will see during the week, it is important to center and normalize the data so that they are centered around 0 with a variance of 1. \n",
    "\n",
    "❓ **Question** ❓ Use the StandardScaler from scikit learn [(see documentation)](https://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.StandardScaler.html) to standardise the data \n",
    "\n",
    "Warning : Use it wisely on the train and test set. _Hint_ : you can check what was done on the multiclass classification tutorial."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "### YOUR CODE HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "❓ **Question** ❓ Plot each of your variable within the train set to check that it is somehow centered around 0 with small variance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### YOUR PLOTS HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model\n",
    "\n",
    "\n",
    "Now that we have the data, we will define a first architecture and run the model \n",
    "\n",
    "❓ **Question** ❓ Initialize a model which has \n",
    "- a first layer with 64 neurons (do not forget the activation and the input dim\n",
    "- a second layer with 32 neurons\n",
    "- a final layer that outputs a predicted value \n",
    "\n",
    "Hint : in the case of a regression, your final layer will look similar to `layers.Dense(SOME_NUMBER, activation='linear')` where `SOME_NUMBER` corresponds to the dimension of the output you want to predict."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def initialize_model():\n",
    "\n",
    "    # Model architecture\n",
    "    ### YOUR CODE HERE\n",
    "    \n",
    "    \n",
    "    # Model optimization : Optimized, loss and metric\n",
    "    model.compile(optimizer='adam',\n",
    "                  loss='mse',       # MSE stands for Mean Square Error\n",
    "                  metrics=['mae'])  # MAE stands for Mean Absolute Error\n",
    "    \n",
    "    return model\n",
    "\n",
    "\n",
    "model = initialize_model()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "❓ **Question** ❓ What can you say about the loss and the metrics?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### YOUR ANSWER HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "❓ **Question** ❓ Run the model on the train data. As in the previous exercise, add `validation_data=(X_test, y_test)` to check the MAE and MSE value on the test set during the iterations\n",
    "and plot the history on the train and test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_loss_mae(history):\n",
    "    plt.plot(history.history['loss'])\n",
    "    plt.plot(history.history['val_loss'])\n",
    "    plt.title('Model loss')\n",
    "    plt.ylabel('Loss')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.legend(['Train', 'Test'], loc='best')\n",
    "    plt.show()\n",
    "    \n",
    "    plt.plot(history.history['mae'])\n",
    "    plt.plot(history.history['val_mae'])\n",
    "    plt.title('Model MAE')\n",
    "    plt.ylabel('MAE')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.legend(['Train', 'Test'], loc='best')\n",
    "    plt.show()\n",
    "    \n",
    "### YOUR CODE HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "❓ **Question** ❓ Try some architecture of your own to get the best possible MAE. (We will see tomorrow how to avoid the overfitting). Especially, you can try to :\n",
    "\n",
    "- Change the number of layers\n",
    "- Change the number of neurons in each layer\n",
    "- Change the activation function within each layer"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": false,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
