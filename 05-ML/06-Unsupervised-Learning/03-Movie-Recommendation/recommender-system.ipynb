{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Recommender Systems\n",
    "\n",
    "Recommender systems are useful for recommending users items based on their past preferences. Recommender systems are generally classified into the following categories:\n",
    "\n",
    "- **Content-based** based on similarity of item attributes (information about items e.g. keywords, categories, etc. and users (preferences, profiles, etc.). For instance, if a user liked Item 1, the recommender system would recommend items with similar characteristics. If we would talk about movies, those characteristics would include producer, starring actors, genre, run time, release date, etc. Typically, this can be done with a binary classification supervised algorithm.\n",
    "\n",
    "\n",
    "- **Collaborative filtering**, which calculates similarity from interactions (e.g. ratings, number of purchases, likes, etc.). This process finds customers who have similar preferences, and then gives recommendations to one customer from a set of items that are new to that particular customer and preferred by other customers with a similar profile. The system makes an assumption that users with similar movie watching habits have similar preferences in general. It finds users who watch videos similar to those the user watches, then identifies videos those similar users have watched, but which the first user has not. Finally, it makes recommendations on that basis. There are 3 approaches to this; user-user collaborative filtering, item-item collaborative filtering and matrix factorization.\n",
    "\n",
    "\n",
    "- New approaches and usually more powerful are **Hybrid systems**, which combine the two aforementioned methods.\n",
    "\n",
    "<img src=\"data/image.png\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The above diagram categorises in detail the different methodologies for building a recommender system.\n",
    "\n",
    "In context to the `movieLens` that will be used later as a sample dataset:\n",
    "- We will suggest different movies based on the content similarity, e.g. genre, cast, etc. applying an item-content filtering\n",
    "- We could also compare the user metadata, such as age and gender, and suggest items to the user that similar users have liked. In that case, we would use a user-content filtering. The `movielens` dataset doesn't contain any user content data, so we will build only an item-item collaborative filtering.\n",
    "\n",
    "**Memory-based** content filtering\n",
    "\n",
    "In memory-based methods there is no model that learns from the data to predict. A pre-computed matrix of similarities is constructed that can be used for movie predic\n",
    "\n",
    "__Load the datasets in three different pandas dataframes__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__remove the '|' that separates the different genres of movies and replace with an empty space__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Filter data to have only movies that have been rated__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature engineering\n",
    "\n",
    "We're gonna create a new feature called `metadata`, that gathers all the text data information we have about a movie : the genre and the tags"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Merge the movies and tags data frames__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Create a new dataframe `df` of unique movies with [`moveId`, `title`, `genres`, `tag`, `metadata`] as columns__\n",
    "\n",
    "Where `metadata` column contains the contatenated string of all `tags` and `genres` related to this movie.   \n",
    "For instance, for Toy Story, the metadata = 'pixar pixar fun Adventure Animation Children Comedy Fantasy'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create a content latent matrix from metadata\n",
    "\n",
    "### Tf-idf\n",
    "\n",
    "Next we need to transform the metadata text to vectors, in order to feed it to our machine learning algorithms. Machine Learning models don't understand text data so we need to encode it.\n",
    "\n",
    "We're gonna use the `TfidfVectorizer` to encode the metadata column. \n",
    "\n",
    "Create this new dataframe with the vectors you get from this tf idf transformation. Every line is now the tf-idf vector for this specific movie."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Take time to understand how Tfidf workds below\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "tfidf = TfidfVectorizer(stop_words='english')\n",
    "tfidf_matrix = tfidf.fit_transform(df['metadata'])\n",
    "tfidf_df = pd.DataFrame(tfidf_matrix.toarray(), index=df.index.tolist())\n",
    "tfidf_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dimensionality reduction\n",
    "\n",
    "Each movie metadata was transformed into a vector of length 1677! (approximately)\n",
    "\n",
    "We can apply dimensionality reduction methods to describe the data (movies) without much loss of information. Truncated singular value decomposition (SVD) is another advanced tool to reduce dimensions.\n",
    "\n",
    "Contrary to PCA, this estimator does not center the data before computing the singular value decomposition. This means it can work with scipy.sparse matrices efficiently. In particular, truncated SVD works on term count/tf-idf matrices. In that context, it is known as latent semantic analysis (LSA).\n",
    "\n",
    "You can look at `TruncatedSVD` class in scikit learn but it's the same principle as PCA\n",
    "\n",
    "__apply the truncated SVD to a number of components (say 25) to reduce the dimension of your tf idf matrix__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# apply TruncatedSVD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot Cumulative percent of variance as a function of the number of components"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see that with only the first 25 components (from initially about 1700) we can explain more than 80% of the variance, which suffices for our study purposes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# keep the first 25 number of latent components."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create a latent matrix from user ratings\n",
    "\n",
    "Beyond metadata, the user ratings is another valuable source of information: A recommender system can recommend a movie that is similar on the basis of user ratings (item-item collaborative filtering).\n",
    "\n",
    "Create a (9724, 610) pivot dataframe containing all user `ratings`, with `movieId` as index, and all `userId` as columns. Replace rating by `0` when missing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we created a dataset with movies as vectors of length 9724.\n",
    "\n",
    "Once again, we will apply SVD so as to keep only the first 200 principal components (out of 610)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Apply cosine similarity in content and colaborative matrices\n",
    "\n",
    "Next, we will use a similarity measure so as to find the top $N$ most similar movies to \"Toy Story\" based on the filtering methods we created. Cosine similarity is one of the similarity measures we can use (`sklearn.metrics.pairwise.cosine_similarity`)\n",
    "\n",
    "__Calculate the cosine similarity of a sample movie (\"Toy Story\") to both content and collaborative latent matrices.__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can also create a hybrid filter, which is an average measure of similarity from both content and collaborative filtering. \n",
    "\n",
    "`hybrid-similarity = (content-similarity + collab-similarity) / 2`\n",
    "\n",
    "__Calculate the average measure of both content and collaborative__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Create a dataframe with the final similarities to Toy Story__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Sort your dataframe by most similar in terms of collaborative similarity__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You should see Toy Story as the most similar movie of course (similarity of 1 for every column)\n",
    "\n",
    "__You can sort on contant as well as hybrid and see which one gives the best recommentation__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": false,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
