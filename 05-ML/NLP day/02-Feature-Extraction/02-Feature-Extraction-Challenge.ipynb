{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2 - Feature extraction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before training Machine learning algorithms, preprocessed text needs to be transformed into numerical data. This process is called feature extraction, or vectorization. \n",
    "\n",
    "Run the code below to load the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.corpus import movie_reviews\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "reviews = []\n",
    "\n",
    "for fileid in movie_reviews.fileids():\n",
    "    tag, filename = fileid.split('/')\n",
    "    reviews.append((tag, movie_reviews.raw(fileid)))\n",
    "\n",
    "df = pd.DataFrame(reviews)\n",
    "df.columns = ['target','reviews']\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import your preprocessing work from the previous exercice and clean the reviews."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Some of the reviews in the dataset are too short to be considered for training. Others are too long. \n",
    "\n",
    "Keep only the reviews that are between 100 and 500 words."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Vectorizer tuning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sklearn's `CountVectorizer` has parameters that control the vectorizing transformations applied to the text prior to model training.  The different vectorizing transformations will themselves impact the result of the model. As such, it is important to fine tune the parameters of the vectorizer in relation to the model that follows.\n",
    "\n",
    "Read the [documentation](https://scikit-learn.org/stable/modules/generated/sklearn.feature_extraction.text.CountVectorizer.html) to find out more about the following vectorizing parameters:\n",
    "- `ngram_range`\n",
    "- `max_df`\n",
    "- `min_df`\n",
    "- `max_features`\n",
    "\n",
    "Optimize those parameters with a Multinomial Naive Bayes model.\n",
    "\n",
    "You need to:\n",
    "\n",
    "- Initiate a `Pipeline` made up of the `CountVectorizer` and `MultinomialNB` model\n",
    "- Create a parameter dictionary for the CountVectorizer\n",
    "- Plug the pipeline and the parameters dictionary to a `GridSearch`\n",
    "\n",
    "[This](https://scikit-learn.org/stable/tutorial/statistical_inference/putting_together.html) should help."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Term Frequency - Inverse Document Frequency (TfIdf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Rather than counting occurences as does the `CountVectorizer`, the `TfidfVectorizer` computes an importance value for each word in its text and according the entire corpus. That value is the product of the TF and the IDF.\n",
    "\n",
    "Following the same steps as with the CountVectorizer, tune your TfidfVectorizer [[doc]](https://scikit-learn.org/stable/modules/generated/sklearn.feature_extraction.text.TfidfVectorizer.html). \n",
    "\n",
    "This time, we also want you to fine tune the Multinomial Naive Bayes model's `alpha` parameter, which can be done within the same `GridSearch`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
