{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1 - Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Text preprocessing consists of transforming raw text into a form that suits your task. The most basic transformations include removing punctuation, lower casing the text, removing numbers. More advanced are lemmatizing, removing stop words, Part-of-Speech tagging. There are many more.. It is important to chose the preprocessing steps according to your task rather than systematically applying them.\n",
    "\n",
    "In this exercice you will learn some basic text preprocessing and apply it to the movie reviews dataset, with which you will build prediction models in the following exercice.\n",
    "\n",
    "Run the code below to load the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.corpus import movie_reviews\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "reviews = []\n",
    "\n",
    "for fileid in movie_reviews.fileids():\n",
    "    tag, filename = fileid.split('/')\n",
    "    reviews.append((tag, movie_reviews.raw(fileid)))\n",
    "\n",
    "df = pd.DataFrame(reviews)\n",
    "df.columns = ['target','reviews']\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Remove Punctuation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Lower Case"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Remove Numbers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Remove StopWords"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\"Stopwords\" are words are so frequently used that for many tasks (but not all), they don't carry much information. Examples are \"any\", \"all\", \"what\"... NLTK has an inbuilt corpus of english stopwords. \n",
    "\n",
    "Import the corpus and use it to remove stop words from the reviews."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Lemmatize"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lemmatizing consists of reducing word derivatives down to their ethymological roots. For example: studies & studying --> study."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
