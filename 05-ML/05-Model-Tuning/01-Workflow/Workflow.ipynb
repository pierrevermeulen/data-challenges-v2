{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Workflow & Hyperparameter Optimization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our dataset describes heart diseases in a binary class problem (1: disease, 0: no disease)\n",
    "\n",
    "Your goal will be to fit KNN to best predict malignant targets by avoiding the maximum false negatives!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "üëá Import the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('heart.csv')\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "X = data.drop(columns=['target'])\n",
    "y = data['target']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Train/Test split"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "üëá Split the data to create your `X_train` `X_test` and `y_train` `y_test`\n",
    "\n",
    "Use a test_size=0.3 and a `random_state=0` to compare with your buddy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Scaling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "‚ùì Scale your training set using the scaler of your choice"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Baseline KNN model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "‚ùì Cross validate a basic KNN classifier on your training set on the using the \"ROC area-under-curve\" metric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Grid search\n",
    "\n",
    "Use KNeighborsClassifier\n",
    "\n",
    "üëá Grid search a KNN's hyperparameter k on the training data.\n",
    "- Search k = [1,5,10,20,50]\n",
    "- 5-fold cross validate\n",
    "- Score with recall"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instanciate model\n",
    "\n",
    "# Hyperparameter Grid\n",
    "\n",
    "# Instanciate Grid Search\n",
    "\n",
    "# Fit data to Grid Search"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "‚ùì According to the grid search, what is the optimal K value?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "‚ùì What is the best score the optimal K value produced?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We now have an idea about where the best k lies, but some of the values we did not try could be better!\n",
    "\n",
    "Re-run grid search with k-values around to your previous best value\n",
    "\n",
    "‚ùì What is the best score and best k?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Optimizing multiple hyperparameters\n",
    "\n",
    "üëá Is the default distance parameter of a KNNClassifier optimal for the task? Run a random search to compute your answer. (look for the parameter 'p' in the [Documentation](https://scikit-learn.org/stable/modules/generated/sklearn.neighbors.KNeighborsClassifier.html))\n",
    "\n",
    "First, let's do a grid search for k and p at the same time. Try 10 combinations, e.g. k = [1, 10, 20, 30, 40]; p = [1, 2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "‚ùì What are the best parameters and the best score?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Random Search\n",
    "\n",
    "Now let's see if a Random Search can find a better combination only 10 tries.\n",
    "\n",
    "üëá Redo the same for `RandomizedSearchCV` but randomly sample `n_neighbors` from a `randint(1,40)` distribition\n",
    "\n",
    "To compare apples to apples, run `RandomizedSearchCV` with `n_iter=10` to have the same number of total combinations to try. Also make sure you use the same scoring method for both, for example accuracy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<details>\n",
    "    <summary>ü§î Is the best score better with the Randomized Search?</summary>\n",
    "\n",
    "\n",
    "It is not guaranteed because it is random, but we know there is a chance that RandomizedSearch will sample it.\n",
    "\n",
    "You can play with np.random.seed() to see that sometimes RandomSearch will outperform GridSearch and sometimes not.\n",
    "\n",
    "It is important to note that our dataset is extremely small and our hyperparameter optimization is thus extremely dependent (and overfitting) on our train/test split. **Always make sure your dataset is much bigger than the total number of hyperparameter combinations you are trying out!**\n",
    "\n",
    "Randomized Search will become more useful even, when we want to search over even more than 2 numerical hyperparameters and sample all of them randomly, for example for SVMs!\n",
    "\n",
    "One thing you can always do is run a coarse grained grid search frst, followed by a more fine grained search around the best parameter that you found. You can also do a randomized search followed by a grid search and vice versa. \n",
    "</details>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Generalization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "üëá This is your final chance to finetune your model: Try to refine your Grid/RandomsearchCV, instanciate your best model and re-fit it on the entire train set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "üëá Time has come to discover its its performance on the **unseen** test set. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "‚ùì Would you consider the optimized model to generalize well?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<details><summary>Hints</summary>\n",
    "\n",
    "Find horrible test performance? You probably foregot to scale your test set too! Re-use your scaler fitted on the train set to transform your test set accordingly!\n",
    "</details>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "üèÅ Congratulation. Please push the exercice once completed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": false,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": true
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
