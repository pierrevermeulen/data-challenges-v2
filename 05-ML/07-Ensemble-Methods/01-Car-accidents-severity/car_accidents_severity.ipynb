{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Instructions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this challenge, you'll try to predict the severity of car accidents, based on features collected from after-crash police investigation\n",
    "\n",
    "This [Kaggle challenge](https://www.kaggle.com/c/accident-severity) comprises of 1,000,000 accidents report, split into multiple `.csv` files.\n",
    "\n",
    "**The goal of the model is to predict the severity of car accidents**. The target variable is called `grav` (for 'gravity') in the file `users.csv`. This variable has four levels, but in this challenge, we'll convert it to a binary classification problem. We will:\n",
    "- Load data into pandas\n",
    "- Create a single DataFrame for our problem, where each row is a user involved in an accident\n",
    "- Extract the features you think would be relevant to predict its severity\n",
    "- Build a data pipeline that gives you a baseline model\n",
    "- Then, iterate on the different phase and try to get the best model! \n",
    "\n",
    "üî• **Today is a special challenge** :\n",
    "- You will send your best score to your batch slack channel!\n",
    "- The winner will present its notebook to the class during the recap session at 5pm üí™"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "‚ö†Ô∏è **Good practices to follow for large exploratory notebooks**\n",
    "- Build your Notebook linearily so that it can always be run from top to bottom without any errors\n",
    "- Clean the outputs of your cells that are not needed\n",
    "- Clean your variables in memory when you don't need them (especially when they are very large). You can use the python built-in function `del`, or the the **Jupyter nbextentions** `variable_inspector`\n",
    "- Make heavy use of `table_of_content` and `collapsable_headings` "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data sourcing\n",
    "\n",
    "Let's get started! The data we want to use is from the `csv` files in `/data/data_training`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "cara = pd.read_csv(\"data/data_training/caracteristics.csv\", encoding=\"ISO-8859-1\")\n",
    "users = pd.read_csv(\"data/data_training/users.csv\", encoding=\"ISO-8859-1\")\n",
    "places = pd.read_csv(\"data/data_training/places.csv\", encoding=\"ISO-8859-1\")\n",
    "vehicles = pd.read_csv(\"data/data_training/vehicles.csv\", encoding=\"ISO-8859-1\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "‚ùì Explore the different tables, and the different variables using `challenge_variable.md`, which provides a description of features. More details can be found [here](https://www.data.gouv.fr/fr/datasets/r/8d4df329-bbbb-434c-9f1f-596d78ad529f) if needed, or in the [Kaggle](https://www.kaggle.com/ahmedlahlou/accidents-in-france-from-2005-to-2016/discussion) discussion channel. Understand"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your code below"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Merge datasets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "‚ùì We will create one single dataset where each row should represent a `user` in a car, by merging the data from the different files dataset.  \n",
    "**Take some time to think about how you would do it yourself**, and only then, read carefully through the code below to understand exactly what we did"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Merge caracteristics and places on 'Num_Acc'\n",
    "data = cara.merge(places, on='Num_Acc')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a common key to merge users amd vehicles on\n",
    "users['Num_Acc_num_veh'] = users['Num_Acc'].map(lambda x: str(x)) + users['num_veh']\n",
    "vehicles['Num_Acc_num_veh'] = vehicles['Num_Acc'].map(lambda x: str(x)) + vehicles['num_veh']\n",
    "# Remove useless columns\n",
    "vehicles = vehicles.drop(columns=['index'])\n",
    "users = users.drop(columns=['index', 'Num_Acc', 'num_veh'])\n",
    "# Merge vehicles and users\n",
    "tmp = vehicles.merge(users, on='Num_Acc_num_veh', how='inner')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merge all datasets on 'Num_Acc'\n",
    "data = data.merge(tmp, on='Num_Acc', how='inner')\n",
    "del tmp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preprocessing\n",
    "\n",
    "We will apply some preprocessing methods like standardization or missing values removal or imputing.\n",
    "Remember to look at `challenge_variable.md` for a description of features."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Clean Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# drop lines without targets (if any)\n",
    "data_cleaned = data[~np.isnan(data.grav)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Check whih features with highest ratio of NaN per column\n",
    "(data_cleaned.isna().sum() / data_cleaned.shape[0]).sort_values(ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove too incomplete features\n",
    "too_incomplete_features=[\n",
    "    'locp', 'actp', 'etatp'\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove features that can be safely considered useless for the predictive power of our model\n",
    "useless_features=[\n",
    "    'v2', 'lat', 'long', 'gps', 'pr1', 'pr', 'v1', 'adr', 'voie',\n",
    "    'index_x', 'Num_Acc', 'Num_Acc_num_veh', 'Num_Acc', 'num_veh', 'index_y',\n",
    "    'jour', 'an',\n",
    "    'dep', 'com', 'env1',\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_cleaned.drop(columns=too_incomplete_features+useless_features, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We now have a `data_cleaned` dataset! Let's now engineer our features as needed"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prepare features and target"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Numerical features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "# List numerical features to process\n",
    "features_numerical = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import RobustScaler, StandardScaler\n",
    "\n",
    "def preprocess_numerical_features(X):\n",
    "    '''\n",
    "    Returns a new DataFrame with\n",
    "    - Missing values replaced by Column Mean\n",
    "    - Features Standard Scaled\n",
    "    - Original Features names kept in the DataFrame\n",
    "    '''\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Check your code below\n",
    "preprocess_numerical_features(data_cleaned[features_numerical])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "‚ùì Do you get a Warning \"A value is trying to be set on a copy of a slice from a DataFrame\"?\n",
    "If so, it may be because you are trying to modify the input DataFrame `data_cleaned`!\n",
    "\n",
    "Read this [important blog on copy vs. view](https://www.practicaldatascience.org/html/views_and_copies_in_pandas.html) of pandas DataFrame and try to solve your warning by yourself\n",
    "\n",
    "\n",
    "\n",
    "<details>\n",
    "    <summary>Hint</summary>\n",
    "\n",
    "`pd.DataFrame.copy()`\n",
    "</details>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (optional) cyclical features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Do you see any cyclical features to process specifically?\n",
    "# This can be done after a first baseline model is created.\n",
    "features_cyclical = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "# YOUR CODE BELOW\n",
    "def preprocess_cyclical_features(X):\n",
    "    '''\n",
    "    Input: DataFrame X\n",
    "    Output: Returns new DataFrame, where all its features X_i have been replaced\n",
    "    by both their sin(2*Pi / cycle_length * X_i) and cos(2*Pi / cycle_length * X_i), and delete initial feature X_i.\n",
    "    '''\n",
    "    pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "### Categorical features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "‚ùì Create the last group of feature (categorical features) without hardcoding them manually. Then, create the associated preprocessing method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "features_categorical = list(set(data_cleaned.columns) - set(features_numerical) - set(features_cyclical) - {'grav'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_categorical_features(X):   \n",
    "    ''' Returns a new DataFrame with dummified columns'''\n",
    "    pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "‚ùì Create the new `data_preprocessed` dataset by concatenating all three preprocessing, and then drop all remaining NaN that could not have been handled previously despite our preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1125397, 216)"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# YOUR CODE BELOW"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Split Dataset\n",
    "‚ùì Create X and y, and don't forget to convert the classification into a binary task.\n",
    "\n",
    "For instance:\n",
    "\n",
    "```python\n",
    "data['grav_binary'] = data['grav'].replace({1: 0, 4: 0, 2: 1, 3: 1})\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create X and y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a smaller dataset (X_small, y_small) for investigation purpose only"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train Test Split using random_state=414\n",
    "# Train Test Split \n",
    "# (let's forget for the sake of this challenge that we are data-leaking a bit on our preprocessing steps above)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "# (optional) Create here a train/eval split within the train set itself.\n",
    "# Some powerfull models (XGBOOST, Neural Network...) which are prone to overfitting on the traning set, needs \"early stopping criteria\", to avoid descending the gradient completely and avoid overfitting."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Features exploration"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You now have a dataset ready for training! \n",
    "**Skip directly to section 5 to get a baseline model working ASAP**, and only then come back to this section 4 if you want to better understand your X and get inspiration for the best model to use, or for some feature selection to reduce model complexity"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "‚ùìInvestigate your X. Are features strongly correlated? Are some feature more important than other?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# YOUR CODE HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Forest-based most important features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "‚ùì Fit a default RandomForestClassifier on a small smaple to estimate the top 20 feature importance. Do they make intuitive sense to your point of view?  Do you see any clear elbow for dimension-reduction?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "# YOUR CODE HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "‚ùì (Optional) There are better ways to estimate feature importance in a RandomForest. Feel free to try to two following options\n",
    "\n",
    "**Option 1** : Recursive-method\n",
    "1. Train a first model, note top1 feature (computed based on the gini-explicative power of the feature, in each tree)\n",
    "2. Remove top1 from your X and retrain a RandomForest. Note top1 feature and it's relative importance\n",
    "3. Loop\n",
    "\n",
    "**Option 2** : Permutation-method ([sklearn.inspection.permutation_importance](https://scikit-learn.org/stable/modules/permutation_importance.html#permutation-importance)), works with any model!\n",
    "1. Train a first model, keep track of its accuracy\n",
    "2. Take one feature and shuffle its columns. Compute new accuracy of the corrupted dataset, and note by how much it has been reduced.\n",
    "3. Loop over all features and rank them by accuracy reduction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# YOUR CODE HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Modeling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Baseline performance metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "‚ùì What is the class balance of your target?  \n",
    "Do you think acccuracy would be a good score?\n",
    "If you don't want to favor any class over the other, what would be a good performance metric for your problem? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<details>\n",
    "    <summary>Answer</summary>\n",
    "\n",
    "In such an unbalanced problem, accuracy is meaningless: A very dumb model predicting always zeros would have great accuracy, to the detriment of the predictive power of class  1, which has precision and recall equal to zero!\n",
    "    \n",
    "The non-weighted mean between both f1 score of each class called `f1_macro` would be a good measure for this type of problem.\n",
    "</details>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Simple Model (A first iteration)\n",
    "\n",
    "‚ùì Create a simple model, fast to train, to classify the severity of the accidents. Start simple. Don't forget to fit on your training set and evaluate the score on your test set. Can you beat the Baseline? What about its `f1_macro` score? Measure the time it takes on the full dataset, with `%%time` "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# YOUR CODE BELOW\n",
    "%%time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# üî•üî•üî• Advanced Models - LeWagon batch contest ! üî•üî•üî•"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "‚ùì Now it's your turn to shine! Play with different models and try to find the best one on your training set!\n",
    "- Send your best `f1_macro` score (as defined above) to your slack channel without saying which model you used!\n",
    "- ‚ö†Ô∏è Only send score tested on a full `y_test` of complete size (30% of 1M rows!) will be taken into account\n",
    "- Feel free to use your X_small for investigation purpose\n",
    "- If it takes too long to train, simplify your model, or use better feature preprocessing/selection\n",
    "\n",
    "The winner will present its notebook to the class during the reboot üí™\n",
    "\n",
    "(Don't forget, your Notebook should be made to be run from top to bottom in one go!)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<details>\n",
    "    <summary>Some hints</summary>\n",
    "Take a closer look at feature engineering: Are there some features we haven't correctly preprocessed?  \n",
    "    \n",
    "Most of the time, a good dataset trumps a good model!\n",
    "</details>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "# YOUR CODE HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (Optional) - Pipeline most steps (prepross & fit) in one single Sklearn Pipeline"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "230.797px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "position": {
    "height": "368px",
    "left": "927px",
    "right": "20px",
    "top": "141px",
    "width": "350px"
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
